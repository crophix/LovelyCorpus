Project brainstorming:

Possible Features
=================

Noise reduction
    remove outliers
      * remove a certain number
      * remove a certain percentage
      * remove any that are a certain distance from the norm

Data validation
    check for missing attributes

Data manipulation
    Normalize data
        change a range of values into a normally distributed set of values

Create data subsets
    break a set of data into training/testing sets

Execute external code
    runs other code on the generated data sets
    must have an intelligent way to handle the arguments

Combine data from multiple sources
    column/attribute matching
    generate a correctly formatted output

Automate boosting and bagging


<Stretch considerations>
========================

Visualization
    visualize the amount of noise possibly

Domain transformations
    FFT maybe

Databases
    generate training sets froma database of information

How to handle non-numeric data?


